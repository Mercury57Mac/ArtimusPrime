{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4202543,"sourceType":"datasetVersion","datasetId":2477766}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport numpy as np \nimport pandas as pd \nfrom PIL import Image\n\ndef process_images_by_simplified_genre(\n    main_image_dir,\n    output_base_dir,\n    target_images_per_simplified_genre=2000,\n    target_image_size=(224, 224)\n):\n    \"\"\"\n    Processes images from detailed genre folders, categorizes them into simplified genres,\n    randomly samples a target number of images per simplified genre (proportionally\n    from contributing detailed folders), resizes them, and saves them to new directories.\n\n    Args:\n        main_image_dir (str): The path to the directory containing all the detailed\n                              genre folders (e.g., 'Abstract_Expressionism', 'Baroque', etc.).\n        output_base_dir (str): The path where the new simplified genre folders\n                               and processed images will be saved.\n        target_images_per_simplified_genre (int): The maximum number of images to\n                                                  select for each simplified genre.\n        target_image_size (tuple): A tuple (width, height) for the desired\n                                   output image size.\n    \"\"\"\n\n    genre_mapping = {\n        # 1. Classical & Pre-Modern Eras (pre-19th century art)\n        \"Early_Renaissance\": \"01_Classical_Pre_Modern\",\n        \"High_Renaissance\": \"01_Classical_Pre_Modern\",\n        \"Northern_Renaissance\": \"01_Classical_Pre_Modern\",\n        \"Mannerism_Late_Renaissance\": \"01_Classical_Pre_Modern\",\n        \"Baroque\": \"01_Classical_Pre_Modern\",\n        \"Rococo\": \"01_Classical_Pre_Modern\",\n\n        # 2. 19th Century Art (Romanticism, Realism, Impressionism, etc.)\n        \"Romanticism\": \"02_19th_Century_Art\",\n        \"Realism\": \"02_19th_Century_Art\",\n        \"Impressionism\": \"02_19th_Century_Art\",\n        \"Post_Impressionism\": \"02_19th_Century_Art\",\n        \"Pointillism\": \"02_19th_Century_Art\",\n        \"Symbolism\": \"02_19th_Century_Art\",\n\n        # 3. Early 20th Century Modernism (Figurative/Expressive)\n        \"Fauvism\": \"03_Early_20th_C_Modernism\",\n        \"Expressionism\": \"03_Early_20th_C_Modernism\",\n        \"Art_Nouveau_Modern\": \"03_Early_20th_C_Modernism\",\n\n        # 4. Cubism & Related Geometric Abstraction\n        \"Cubism\": \"04_Cubism_Geometric_Abstraction\",\n        \"Analytical_Cubism\": \"04_Cubism_Geometric_Abstraction\",\n        \"Synthetic_Cubism\": \"04_Cubism_Geometric_Abstraction\",\n\n        # 5. Mid-20th Century Abstraction (Abstract Expressionism, Color Field)\n        \"Action_painting\": \"05_Mid_20th_C_Abstraction\",\n        \"Color_Field_Painting\": \"05_Mid_20th_C_Abstraction\",\n        \"Abstract_Expressionism\": \"05_Mid_20th_C_Abstraction\",\n\n        # 6. Pop Art\n        \"Pop_Art\": \"06_Pop_Art\",\n\n        # 7. Minimalism\n        \"Minimalism\": \"07_Minimalism\",\n\n        # 8. Contemporary Realism (Art after Mid-20th C, distinct from Pop Art)\n        \"New_Realism\": \"08_Contemporary_Realism\",\n        \"Contemporary_Realism\": \"08_Contemporary_Realism\",\n\n        # 9. Naive and Primitivism\n        \"Naive_Art_Primitivism\": \"09_Naive_Primitivism\",\n\n        # 10. Asian / Other Cultural Art\n        \"Ukiyo_e\": \"10_Asian_Cultural_Art\"\n    }\n\n    \n    os.makedirs(output_base_dir, exist_ok=True)\n    print(f\"Output directory '{output_base_dir}' ensured.\")\n\n    # Create a reverse map for easy lookup: simplified_genre -> list of detailed_genres\n    simplified_to_detailed_map = {}\n    for detailed, simplified in genre_mapping.items():\n        if simplified not in simplified_to_detailed_map:\n            simplified_to_detailed_map[simplified] = []\n        simplified_to_detailed_map[simplified].append(detailed)\n\n    # Allowed image extensions\n    image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')\n\n    # Process each simplified genre\n    for simplified_genre, detailed_genres in simplified_to_detailed_map.items():\n        print(f\"\\nProcessing Simplified Genre: {simplified_genre}\")\n        output_simplified_dir = os.path.join(output_base_dir, simplified_genre)\n        os.makedirs(output_simplified_dir, exist_ok=True)\n\n        all_images_in_simplified_category = []\n        detailed_genre_image_lists = {} # Stores list of image paths for each detailed genre\n\n        # First pass: Collect all image paths and count total available\n        for detailed_genre_name in detailed_genres:\n            detailed_genre_path = os.path.join(main_image_dir, detailed_genre_name)\n            if os.path.isdir(detailed_genre_path):\n                images_in_folder = [\n                    os.path.join(detailed_genre_path, f)\n                    for f in os.listdir(detailed_genre_path)\n                    if f.lower().endswith(image_extensions)\n                ]\n                detailed_genre_image_lists[detailed_genre_name] = images_in_folder\n                all_images_in_simplified_category.extend(images_in_folder)\n            else:\n                print(f\"  Warning: Detailed genre folder '{detailed_genre_path}' not found. Skipping.\")\n\n        num_total_available = len(all_images_in_simplified_category)\n        if num_total_available == 0:\n            print(f\"  No images found for simplified genre '{simplified_genre}'. Skipping.\")\n            continue\n\n       \n        effective_target_for_category = min(target_images_per_simplified_genre, num_total_available)\n        print(f\"  Total images available: {num_total_available}. Target for category: {effective_target_for_category}\")\n\n        selected_images_paths = []\n\n        remaining_quota = effective_target_for_category\n        remaining_detailed_genres = list(detailed_genre_image_lists.keys())\n\n        # Distribute images in rounds until quota is met or no more images available\n        while remaining_quota > 0 and len(remaining_detailed_genres) > 0:\n            num_detailed_genres_to_sample = len(remaining_detailed_genres)\n            if num_detailed_genres_to_sample == 0:\n                break # Should not happen if loop condition is correct, but for safety\n\n            # Calculate a base number of images to try and take from each remaining detailed genre\n            base_take_per_genre = remaining_quota // num_detailed_genres_to_sample\n            if base_take_per_genre == 0 and remaining_quota > 0:\n                base_take_per_genre = 1\n\n            next_round_remaining_detailed_genres = []\n            taken_this_round = 0\n\n            for detailed_genre_name in remaining_detailed_genres:\n                images_list = detailed_genre_image_lists[detailed_genre_name]\n                already_selected_count = sum(1 for p in selected_images_paths if os.path.dirname(p) == os.path.join(main_image_dir, detailed_genre_name))\n                available_to_take = len(images_list) - already_selected_count\n\n                if available_to_take > 0:\n                    num_to_take = min(base_take_per_genre, available_to_take, remaining_quota - taken_this_round)\n                    if num_to_take <= 0 and remaining_quota - taken_this_round > 0 and available_to_take > 0:\n                        # Ensure at least one is taken if quota is still available\n                        num_to_take = 1\n\n                    if num_to_take > 0:\n                        unselected_images = [img for img in images_list if img not in selected_images_paths]\n                        sample = random.sample(unselected_images, num_to_take)\n                        selected_images_paths.extend(sample)\n                        taken_this_round += len(sample)\n                        if len(selected_images_paths) >= effective_target_for_category:\n                            break # Met the target\n\n                    if available_to_take > num_to_take: \n                        next_round_remaining_detailed_genres.append(detailed_genre_name)\n               \n\n            remaining_quota -= taken_this_round\n            remaining_detailed_genres = next_round_remaining_detailed_genres\n\n            if taken_this_round == 0 and remaining_quota > 0 and len(remaining_detailed_genres) > 0:\n                # If no images were taken in a round but quota remains and genres are available\n                # it means base_take_per_genre was too small for some reason\n                for detailed_genre_name in remaining_detailed_genres:\n                    if remaining_quota <= 0: break\n                    images_list = detailed_genre_image_lists[detailed_genre_name]\n                    unselected_images = [img for img in images_list if img not in selected_images_paths]\n                    if len(unselected_images) > 0:\n                        sample = random.sample(unselected_images, 1)\n                        selected_images_paths.extend(sample)\n                        remaining_quota -= 1\n                        if len(selected_images_paths) >= effective_target_for_category:\n                            break\n\n        # If we have slightly more than effective_target_for_category due to rounding\n        # or if previous logic didn't perfectly hit the target but collected enough trim it down\n        if len(selected_images_paths) > effective_target_for_category:\n            selected_images_paths = random.sample(selected_images_paths, effective_target_for_category)\n        elif len(selected_images_paths) < effective_target_for_category and num_total_available >= effective_target_for_category:\n             # This indicates an issue in the sampling loop, should not happen if logic is perfect,\n             # but as a fallback, take randomly from all if still under target and total available allows.\n             print(f\"  Warning: Target not fully met proportionally. Attempting final random fill. \"\n                   f\"Current: {len(selected_images_paths)}, Target: {effective_target_for_category}\")\n             all_unselected = [img for img in all_images_in_simplified_category if img not in selected_images_paths]\n             needed = effective_target_for_category - len(selected_images_paths)\n             if needed > 0 and len(all_unselected) > 0:\n                 additional = random.sample(all_unselected, min(needed, len(all_unselected)))\n                 selected_images_paths.extend(additional)\n\n\n        print(f\"  Selected {len(selected_images_paths)} images for {simplified_genre}.\")\n\n        # Process and save the selected images\n        for i, img_path in enumerate(selected_images_paths):\n            try:\n                img = Image.open(img_path).convert(\"RGB\") # Ensure RGB mode\n                img = img.resize(target_image_size, Image.Resampling.LANCZOS) \n                original_filename = os.path.basename(img_path)\n                filename_base, file_extension = os.path.splitext(original_filename)\n                output_filename = f\"{filename_base}_{i}{file_extension}\" # Append index for uniqueness\n                output_path = os.path.join(output_simplified_dir, output_filename)\n                img.save(output_path)\n            except FileNotFoundError:\n                print(f\"    Error: Image file not found: {img_path}\")\n            except Image.UnidentifiedImageError:\n                print(f\"    Error: Cannot identify image file (corrupted or unsupported format): {img_path}\")\n            except Exception as e:\n                print(f\"    Error processing {img_path}: {e}\")\n\n    print(\"\\nImage processing complete.\")\n\n\nmain_genres_directory = '/kaggle/input/wikiart'\n\n# This will be the directory where new folders \noutput_standardized_images_dir = '/kaggle/working/'\n\n# Call the function to start processing\nprocess_images_by_simplified_genre(\n    main_genres_directory,\n    output_standardized_images_dir,\n    target_images_per_simplified_genre=2000, # Max 2000 images per simplified genre\n    target_image_size=(224, 224) # Standardize to 224x224 pixels\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import (\n    Dense,\n    GlobalAveragePooling2D,\n    Input,\n    RandomFlip,\n    RandomRotation,\n    RandomZoom,\n    RandomContrast\n)\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport os\nimport matplotlib.pyplot as plt\nimport math\n\n\n# --- Set Global Policy for Mixed Precision Training ---\ntry:\n    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n    print(\"Mixed precision training enabled.\")\nexcept Exception as e:\n    print(f\"Could not enable mixed precision: {e}\")\n\n# --- Define Paths and Constants ---\nPROCESSED_IMAGES_DIR = '/kaggle/input/imageclassification-v1'\nMODEL_SAVE_PATH = '/kaggle/working/efficient_art_classifier_final.keras'\n\n# Image dimensions and training parameters\nIMG_HEIGHT, IMG_WIDTH = 224, 224\nEPOCHS = 150\nBATCH_SIZE = 128\nAUTOTUNE = tf.data.AUTOTUNE\n\n# --- Create 3-Way Data Split ---\nprint(\"\\nSetting up 3-way data split (70% train, 15% val, 15% test)...\")\n\n# Load the full dataset from the directory\nfull_ds = tf.keras.utils.image_dataset_from_directory(\n    PROCESSED_IMAGES_DIR,\n    seed=123,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE\n)\n\nclass_names = full_ds.class_names\nnum_classes = len(class_names)\nprint(f\"Discovered {num_classes} classes: {class_names}\")\n\n# Get the full size of the dataset\ndataset_size = tf.data.experimental.cardinality(full_ds).numpy()\ntrain_size = int(0.7 * dataset_size)\nval_size = int(0.15 * dataset_size)\ntest_size = int(0.15 * dataset_size)\n\n# Shuffle the dataset before splitting\nfull_ds = full_ds.shuffle(buffer_size=1000, seed=123, reshuffle_each_iteration=False)\n\n# Create the splits \ntrain_ds = full_ds.take(train_size)\nval_ds = full_ds.skip(train_size).take(val_size)\ntest_ds = full_ds.skip(train_size + val_size).take(test_size)\n\nprint(f\"Training set size: ~{train_size * BATCH_SIZE} images\")\nprint(f\"Validation set size: ~{val_size * BATCH_SIZE} images\")\nprint(f\"Test set size: ~{test_size * BATCH_SIZE} images\")\n\n# Configure datasets for performance\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\ntest_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n# --- Set up Multi-GPU Strategy ---\nstrategy = tf.distribute.MirroredStrategy()\nprint(f\"\\nTraining with {strategy.num_replicas_in_sync} GPUs.\")\n\n# --- Build and Compile Model within Strategy Scope ---\nwith strategy.scope():\n    print(\"Building EfficientNetB0 model for fine-tuning\")\n\n    data_augmentation = Sequential([\n        RandomFlip(\"horizontal\"),\n        RandomRotation(0.2),\n        RandomZoom(0.2),\n        RandomContrast(0.2),\n    ], name='data_augmentation')\n\n    inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n    x = data_augmentation(inputs)\n\n    base_model = EfficientNetB0(\n        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n        include_top=False,\n        weights='imagenet'\n    )\n\n    base_model.trainable = True\n    fine_tune_at = 30 # Number of unfrozen layers \n    print(f\"Unfreezing the top {fine_tune_at} layers of the base model.\")\n    for layer in base_model.layers[:-fine_tune_at]:\n        layer.trainable = False\n\n    x = base_model(x, training=True)\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(128, activation='relu')(x)\n    predictions = Dense(num_classes, activation='softmax', dtype='float32')(x)\n    model = Model(inputs, predictions)\n\n    # Compile the model with gradient clipping for stability\n    optimizer = Adam(learning_rate=1e-5, clipnorm=1.0)\n    print(f\"Compiling model with Adam optimizer (lr={optimizer.learning_rate.numpy()}, clipnorm=1.0).\")\n    model.compile(\n        optimizer=optimizer,\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\nprint(\"\\n--- Model Summary ---\")\nmodel.summary()\n\n# --- Configure Callbacks ---\nearly_stopping_callback = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    mode='min',\n    min_delta=0.001,\n    verbose=1,\n    restore_best_weights=True\n)\n\n# --- Train the Model ---\nprint(f\"\\nStarting model fine-tuning for up to {EPOCHS} epochs...\")\nhistory = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    validation_data=val_ds,\n    callbacks=[early_stopping_callback]\n)\nprint(\"\\nModel training completed.\")\n\n# --- Final Evaluation on the Independent Test Set ---\nprint(\"\\n Evaluating final model on the independent test set...\")\ntest_loss, test_accuracy = model.evaluate(test_ds)\nprint(f\"Test Set Loss: {test_loss:.4f}\")\nprint(f\"Test Set Accuracy: {test_accuracy:.4f}\")\n\n# --- Save Model ---\nmodel.save(MODEL_SAVE_PATH)\nprint(f\"\\nModel saved to: {MODEL_SAVE_PATH}\")\n\n# --- Plot Training History ---\nprint(\"\\nPlotting training history...\")\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport pathlib\n\n# --- Configuration ---\n# Adjust these paths to match your project setup\nMODEL_PATH = '/kaggle/working/efficient_art_classifier_final.keras'\nPROCESSED_IMAGES_DIR = '/kaggle/input/imageclassification-v1'\n\n# Image and batch settings (must match the training script)\nIMG_HEIGHT, IMG_WIDTH = 224, 224\nBATCH_SIZE = 128\nAUTOTUNE = tf.data.AUTOTUNE\n\nprint(\"--- Loading Model and Data ---\")\n\n# Load the trained model\nmodel = tf.keras.models.load_model(MODEL_PATH)\nprint(f\"Model loaded from {MODEL_PATH}\")\n\n# Create a Stratified 3-Way Data Split\nprint(\"\\n--- Creating Stratified Data Splits (70/15/15) ---\")\ndata_dir = pathlib.Path(PROCESSED_IMAGES_DIR)\n\n# Get all image paths and their corresponding labels\nall_paths = list(data_dir.glob('*/*'))\nall_paths = [str(p) for p in all_paths]\nclass_names = sorted([item.name for item in data_dir.glob('*') if item.is_dir()])\nlabel_to_index = dict((name, index) for index, name in enumerate(class_names))\nall_labels = [label_to_index[pathlib.Path(p).parent.name] for p in all_paths]\n\nprint(f\"Found {len(all_paths)} images belonging to {len(class_names)} classes.\")\n\n# --- Seed Set the same as Model Training To Ensure Testing Data is Consistent ---\n# First split 70% train, 30% temp \ntrain_paths, temp_paths, train_labels, temp_labels = train_test_split(\n    all_paths, all_labels, test_size=0.30, random_state=123, stratify=all_labels\n)\n\n# Second split 15% validation, 15% test (split the 30% temp set in half)\nval_paths, test_paths, val_labels, test_labels = train_test_split(\n    temp_paths, temp_labels, test_size=0.50, random_state=123, stratify=temp_labels\n)\n\nprint(f\"Training set size: {len(train_paths)}\")\nprint(f\"Validation set size: {len(val_paths)}\")\nprint(f\"Test set size: {len(test_paths)}\")\n\n# Function to load and process images\ndef load_and_preprocess_image(path, label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n    return image, label\n\n# Create tf.data.Dataset objects from the file paths\ntest_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\ntest_ds = test_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\nprint(\"Test dataset created successfully with stratification.\")\n\n\n#  Get Predictions and True Labels\nprint(\"\\n--- Generating Predictions on Test Set ---\")\npredictions_raw = model.predict(test_ds)\npredicted_labels = np.argmax(predictions_raw, axis=1)\n\n# The true labels are already available from the split\ntrue_labels = np.array(test_labels)\n\n# This is a check to ensure the test set is not empty or malformed\nif len(true_labels) == 0:\n    raise ValueError(\"The test dataset is empty. Check the data splitting logic.\")\nif len(true_labels) != len(predicted_labels):\n    print(f\"Warning: Mismatch in number of true labels ({len(true_labels)}) and predicted labels ({len(predicted_labels)}).\")\n    true_labels = true_labels[:len(predicted_labels)]\n\nprint(\"Predictions and true labels extracted.\")\n\n# --- Quantitative Evaluation ---\n\n#  Top-k Accuracy\nprint(\"\\n--- Top-k Accuracy ---\")\n# Top-1 Accuracy is the standard accuracy\ntop1_accuracy = np.mean(predicted_labels == true_labels)\nprint(f\"Top-1 Accuracy (Standard Accuracy): {top1_accuracy:.4f}\")\n\n# Top-3 Accuracy\n# Get the indices of the top 3 predictions for each image\ntop3_predictions_indices = np.argsort(predictions_raw, axis=1)[:, -3:]\n\n# Check if the true label is in the top 3 predictions for each sample\ntop3_correct = [1 if true_labels[i] in top3_predictions_indices[i] else 0 for i in range(len(true_labels))]\ntop3_accuracy = np.mean(top3_correct)\nprint(f\"Top-3 Accuracy: {top3_accuracy:.4f}\")\n\n\n#  Classification Report (Precision, Recall, F1-Score)\nprint(\"\\n--- Classification Report ---\")\nreport = classification_report(true_labels, predicted_labels, target_names=class_names)\nprint(report)\n\n#  Confusion Matrix\nprint(\"\\n--- Confusion Matrix ---\")\ncm = confusion_matrix(true_labels, predicted_labels)\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix')\nplt.ylabel('Actual Label')\nplt.xlabel('Predicted Label')\nplt.show()\n\n# --- Qualitative Evaluation ---\n\n#  Visualize Misclassified Images\nprint(\"\\n--- Analyzing Misclassified Images ---\")\nmisclassified_indices = np.where(predicted_labels != true_labels)[0]\nnum_images_to_show = 12\nif len(misclassified_indices) > num_images_to_show:\n    selected_indices = np.random.choice(misclassified_indices, size=num_images_to_show, replace=False)\nelse:\n    selected_indices = misclassified_indices\n\nplt.figure(figsize=(15, 15))\nfor i, index in enumerate(selected_indices):\n    path = test_paths[index]\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    \n    true_label_name = class_names[true_labels[index]]\n    pred_label_name = class_names[predicted_labels[index]]\n    \n    plt.subplot(4, 4, i + 1)\n    plt.imshow(image)\n    plt.title(f\"True: {true_label_name}\\nPred: {pred_label_name}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}